{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 11.0,
  "eval_steps": 500,
  "global_step": 286,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.38461538461538464,
      "grad_norm": 225.41221618652344,
      "learning_rate": 4.5e-05,
      "loss": 34.753,
      "step": 10
    },
    {
      "epoch": 0.7692307692307693,
      "grad_norm": 244.21096801757812,
      "learning_rate": 4.965116279069767e-05,
      "loss": 36.7595,
      "step": 20
    },
    {
      "epoch": 1.0,
      "eval_loss": 41.280357360839844,
      "eval_runtime": 0.8239,
      "eval_samples_per_second": 6.069,
      "eval_steps_per_second": 6.069,
      "step": 26
    },
    {
      "epoch": 1.1538461538461537,
      "grad_norm": 2173.403564453125,
      "learning_rate": 4.926356589147287e-05,
      "loss": 40.343,
      "step": 30
    },
    {
      "epoch": 1.5384615384615383,
      "grad_norm": 1109.9688720703125,
      "learning_rate": 4.887596899224807e-05,
      "loss": 40.5348,
      "step": 40
    },
    {
      "epoch": 1.9230769230769231,
      "grad_norm": 693.503662109375,
      "learning_rate": 4.848837209302326e-05,
      "loss": 42.2146,
      "step": 50
    },
    {
      "epoch": 2.0,
      "eval_loss": 40.478214263916016,
      "eval_runtime": 0.8271,
      "eval_samples_per_second": 6.045,
      "eval_steps_per_second": 6.045,
      "step": 52
    },
    {
      "epoch": 2.3076923076923075,
      "grad_norm": 2096.9267578125,
      "learning_rate": 4.810077519379845e-05,
      "loss": 37.3249,
      "step": 60
    },
    {
      "epoch": 2.6923076923076925,
      "grad_norm": 465.81317138671875,
      "learning_rate": 4.7713178294573647e-05,
      "loss": 37.4473,
      "step": 70
    },
    {
      "epoch": 3.0,
      "eval_loss": 39.59844207763672,
      "eval_runtime": 0.8247,
      "eval_samples_per_second": 6.063,
      "eval_steps_per_second": 6.063,
      "step": 78
    },
    {
      "epoch": 3.076923076923077,
      "grad_norm": 443.1934509277344,
      "learning_rate": 4.732558139534884e-05,
      "loss": 41.9322,
      "step": 80
    },
    {
      "epoch": 3.4615384615384617,
      "grad_norm": 1969.6624755859375,
      "learning_rate": 4.693798449612403e-05,
      "loss": 42.967,
      "step": 90
    },
    {
      "epoch": 3.8461538461538463,
      "grad_norm": 246.99562072753906,
      "learning_rate": 4.6550387596899224e-05,
      "loss": 32.7188,
      "step": 100
    },
    {
      "epoch": 4.0,
      "eval_loss": 39.728660583496094,
      "eval_runtime": 0.8246,
      "eval_samples_per_second": 6.064,
      "eval_steps_per_second": 6.064,
      "step": 104
    },
    {
      "epoch": 4.230769230769231,
      "grad_norm": 588.3585205078125,
      "learning_rate": 4.616279069767442e-05,
      "loss": 36.1152,
      "step": 110
    },
    {
      "epoch": 4.615384615384615,
      "grad_norm": 158.35748291015625,
      "learning_rate": 4.577519379844962e-05,
      "loss": 32.8665,
      "step": 120
    },
    {
      "epoch": 5.0,
      "grad_norm": 1074.762939453125,
      "learning_rate": 4.538759689922481e-05,
      "loss": 35.3027,
      "step": 130
    },
    {
      "epoch": 5.0,
      "eval_loss": 39.13011932373047,
      "eval_runtime": 0.818,
      "eval_samples_per_second": 6.112,
      "eval_steps_per_second": 6.112,
      "step": 130
    },
    {
      "epoch": 5.384615384615385,
      "grad_norm": 868.2745971679688,
      "learning_rate": 4.5e-05,
      "loss": 37.1337,
      "step": 140
    },
    {
      "epoch": 5.769230769230769,
      "grad_norm": 436.4163818359375,
      "learning_rate": 4.46124031007752e-05,
      "loss": 33.4906,
      "step": 150
    },
    {
      "epoch": 6.0,
      "eval_loss": 38.52240753173828,
      "eval_runtime": 0.818,
      "eval_samples_per_second": 6.112,
      "eval_steps_per_second": 6.112,
      "step": 156
    },
    {
      "epoch": 6.153846153846154,
      "grad_norm": 368.0225524902344,
      "learning_rate": 4.422480620155039e-05,
      "loss": 35.2207,
      "step": 160
    },
    {
      "epoch": 6.538461538461538,
      "grad_norm": 344.4420166015625,
      "learning_rate": 4.383720930232558e-05,
      "loss": 33.6272,
      "step": 170
    },
    {
      "epoch": 6.923076923076923,
      "grad_norm": 666.1748046875,
      "learning_rate": 4.3449612403100775e-05,
      "loss": 36.686,
      "step": 180
    },
    {
      "epoch": 7.0,
      "eval_loss": 38.06536102294922,
      "eval_runtime": 0.8148,
      "eval_samples_per_second": 6.137,
      "eval_steps_per_second": 6.137,
      "step": 182
    },
    {
      "epoch": 7.3076923076923075,
      "grad_norm": 966.5900268554688,
      "learning_rate": 4.306201550387597e-05,
      "loss": 39.6128,
      "step": 190
    },
    {
      "epoch": 7.6923076923076925,
      "grad_norm": 181.18594360351562,
      "learning_rate": 4.2674418604651164e-05,
      "loss": 35.8264,
      "step": 200
    },
    {
      "epoch": 8.0,
      "eval_loss": 37.75676345825195,
      "eval_runtime": 0.8168,
      "eval_samples_per_second": 6.121,
      "eval_steps_per_second": 6.121,
      "step": 208
    },
    {
      "epoch": 8.076923076923077,
      "grad_norm": 4774.07080078125,
      "learning_rate": 4.228682170542636e-05,
      "loss": 38.9905,
      "step": 210
    },
    {
      "epoch": 8.461538461538462,
      "grad_norm": 593.8502807617188,
      "learning_rate": 4.1899224806201554e-05,
      "loss": 30.8745,
      "step": 220
    },
    {
      "epoch": 8.846153846153847,
      "grad_norm": 469.2909240722656,
      "learning_rate": 4.151162790697675e-05,
      "loss": 36.0712,
      "step": 230
    },
    {
      "epoch": 9.0,
      "eval_loss": 36.7779426574707,
      "eval_runtime": 0.8588,
      "eval_samples_per_second": 5.822,
      "eval_steps_per_second": 5.822,
      "step": 234
    },
    {
      "epoch": 9.23076923076923,
      "grad_norm": 440.8512268066406,
      "learning_rate": 4.1124031007751937e-05,
      "loss": 37.9032,
      "step": 240
    },
    {
      "epoch": 9.615384615384615,
      "grad_norm": 1295.514404296875,
      "learning_rate": 4.073643410852713e-05,
      "loss": 35.1878,
      "step": 250
    },
    {
      "epoch": 10.0,
      "grad_norm": 590.2252197265625,
      "learning_rate": 4.0348837209302326e-05,
      "loss": 33.149,
      "step": 260
    },
    {
      "epoch": 10.0,
      "eval_loss": 36.02083969116211,
      "eval_runtime": 0.8199,
      "eval_samples_per_second": 6.098,
      "eval_steps_per_second": 6.098,
      "step": 260
    },
    {
      "epoch": 10.384615384615385,
      "grad_norm": 2998.2265625,
      "learning_rate": 3.996124031007752e-05,
      "loss": 36.9405,
      "step": 270
    },
    {
      "epoch": 10.76923076923077,
      "grad_norm": 218.56072998046875,
      "learning_rate": 3.9573643410852715e-05,
      "loss": 34.3034,
      "step": 280
    },
    {
      "epoch": 11.0,
      "eval_loss": 34.85968780517578,
      "eval_runtime": 0.9919,
      "eval_samples_per_second": 5.041,
      "eval_steps_per_second": 5.041,
      "step": 286
    }
  ],
  "logging_steps": 10,
  "max_steps": 1300,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 50,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 2098195427328.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
