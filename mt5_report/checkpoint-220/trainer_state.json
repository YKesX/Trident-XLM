{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 20.0,
  "eval_steps": 500,
  "global_step": 220,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.45454545454545453,
      "grad_norm": 979.2210693359375,
      "learning_rate": 8e-05,
      "loss": 36.6579,
      "step": 5
    },
    {
      "epoch": 0.9090909090909091,
      "grad_norm": 184.16046142578125,
      "learning_rate": 9.813953488372092e-05,
      "loss": 40.3252,
      "step": 10
    },
    {
      "epoch": 1.0,
      "eval_loss": 21.344078063964844,
      "eval_runtime": 0.4027,
      "eval_samples_per_second": 4.967,
      "eval_steps_per_second": 2.483,
      "step": 11
    },
    {
      "epoch": 1.3636363636363638,
      "grad_norm": 345.04327392578125,
      "learning_rate": 9.58139534883721e-05,
      "loss": 40.73,
      "step": 15
    },
    {
      "epoch": 1.8181818181818183,
      "grad_norm": 2346.4296875,
      "learning_rate": 9.348837209302326e-05,
      "loss": 39.7517,
      "step": 20
    },
    {
      "epoch": 2.0,
      "eval_loss": 20.76093101501465,
      "eval_runtime": 0.4002,
      "eval_samples_per_second": 4.998,
      "eval_steps_per_second": 2.499,
      "step": 22
    },
    {
      "epoch": 2.2727272727272725,
      "grad_norm": 310.3006896972656,
      "learning_rate": 9.116279069767443e-05,
      "loss": 37.9278,
      "step": 25
    },
    {
      "epoch": 2.7272727272727275,
      "grad_norm": 355.9910583496094,
      "learning_rate": 8.883720930232558e-05,
      "loss": 37.5817,
      "step": 30
    },
    {
      "epoch": 3.0,
      "eval_loss": 20.658126831054688,
      "eval_runtime": 0.3999,
      "eval_samples_per_second": 5.001,
      "eval_steps_per_second": 2.501,
      "step": 33
    },
    {
      "epoch": 3.1818181818181817,
      "grad_norm": 254.7224884033203,
      "learning_rate": 8.651162790697674e-05,
      "loss": 39.999,
      "step": 35
    },
    {
      "epoch": 3.6363636363636362,
      "grad_norm": 2971.61279296875,
      "learning_rate": 8.418604651162792e-05,
      "loss": 39.1082,
      "step": 40
    },
    {
      "epoch": 4.0,
      "eval_loss": 20.572240829467773,
      "eval_runtime": 0.3978,
      "eval_samples_per_second": 5.028,
      "eval_steps_per_second": 2.514,
      "step": 44
    },
    {
      "epoch": 4.090909090909091,
      "grad_norm": 346.7848815917969,
      "learning_rate": 8.186046511627907e-05,
      "loss": 37.9786,
      "step": 45
    },
    {
      "epoch": 4.545454545454545,
      "grad_norm": 368.4843444824219,
      "learning_rate": 7.953488372093023e-05,
      "loss": 41.1547,
      "step": 50
    },
    {
      "epoch": 5.0,
      "grad_norm": 294.56903076171875,
      "learning_rate": 7.72093023255814e-05,
      "loss": 38.6602,
      "step": 55
    },
    {
      "epoch": 5.0,
      "eval_loss": 20.74765396118164,
      "eval_runtime": 0.3962,
      "eval_samples_per_second": 5.048,
      "eval_steps_per_second": 2.524,
      "step": 55
    },
    {
      "epoch": 5.454545454545454,
      "grad_norm": 744.9652709960938,
      "learning_rate": 7.488372093023255e-05,
      "loss": 41.6834,
      "step": 60
    },
    {
      "epoch": 5.909090909090909,
      "grad_norm": 270.0061950683594,
      "learning_rate": 7.255813953488373e-05,
      "loss": 37.6636,
      "step": 65
    },
    {
      "epoch": 6.0,
      "eval_loss": 21.161508560180664,
      "eval_runtime": 0.4035,
      "eval_samples_per_second": 4.957,
      "eval_steps_per_second": 2.479,
      "step": 66
    },
    {
      "epoch": 6.363636363636363,
      "grad_norm": 308.8807373046875,
      "learning_rate": 7.023255813953489e-05,
      "loss": 36.2464,
      "step": 70
    },
    {
      "epoch": 6.818181818181818,
      "grad_norm": 334.023681640625,
      "learning_rate": 6.790697674418604e-05,
      "loss": 38.7135,
      "step": 75
    },
    {
      "epoch": 7.0,
      "eval_loss": 21.28549575805664,
      "eval_runtime": 0.3986,
      "eval_samples_per_second": 5.017,
      "eval_steps_per_second": 2.509,
      "step": 77
    },
    {
      "epoch": 7.2727272727272725,
      "grad_norm": 448.3353271484375,
      "learning_rate": 6.558139534883721e-05,
      "loss": 41.1236,
      "step": 80
    },
    {
      "epoch": 7.7272727272727275,
      "grad_norm": 221.2171630859375,
      "learning_rate": 6.325581395348838e-05,
      "loss": 39.9229,
      "step": 85
    },
    {
      "epoch": 8.0,
      "eval_loss": 21.20574188232422,
      "eval_runtime": 0.4017,
      "eval_samples_per_second": 4.979,
      "eval_steps_per_second": 2.489,
      "step": 88
    },
    {
      "epoch": 8.181818181818182,
      "grad_norm": 1765.206298828125,
      "learning_rate": 6.0930232558139536e-05,
      "loss": 41.4609,
      "step": 90
    },
    {
      "epoch": 8.636363636363637,
      "grad_norm": 440.681640625,
      "learning_rate": 5.8604651162790704e-05,
      "loss": 33.5881,
      "step": 95
    },
    {
      "epoch": 9.0,
      "eval_loss": 21.17901039123535,
      "eval_runtime": 0.3969,
      "eval_samples_per_second": 5.039,
      "eval_steps_per_second": 2.519,
      "step": 99
    },
    {
      "epoch": 9.090909090909092,
      "grad_norm": 227.68423461914062,
      "learning_rate": 5.627906976744186e-05,
      "loss": 35.426,
      "step": 100
    },
    {
      "epoch": 9.545454545454545,
      "grad_norm": 524.5079345703125,
      "learning_rate": 5.3953488372093034e-05,
      "loss": 37.699,
      "step": 105
    },
    {
      "epoch": 10.0,
      "grad_norm": 26.55435562133789,
      "learning_rate": 5.162790697674419e-05,
      "loss": 36.778,
      "step": 110
    },
    {
      "epoch": 10.0,
      "eval_loss": 21.119117736816406,
      "eval_runtime": 0.3996,
      "eval_samples_per_second": 5.005,
      "eval_steps_per_second": 2.503,
      "step": 110
    },
    {
      "epoch": 10.454545454545455,
      "grad_norm": 301.1494445800781,
      "learning_rate": 4.930232558139535e-05,
      "loss": 34.8905,
      "step": 115
    },
    {
      "epoch": 10.909090909090908,
      "grad_norm": 191.72586059570312,
      "learning_rate": 4.697674418604651e-05,
      "loss": 37.15,
      "step": 120
    },
    {
      "epoch": 11.0,
      "eval_loss": 20.99148941040039,
      "eval_runtime": 0.402,
      "eval_samples_per_second": 4.975,
      "eval_steps_per_second": 2.488,
      "step": 121
    },
    {
      "epoch": 11.363636363636363,
      "grad_norm": 314.2021789550781,
      "learning_rate": 4.465116279069767e-05,
      "loss": 34.705,
      "step": 125
    },
    {
      "epoch": 11.818181818181818,
      "grad_norm": 912.9202880859375,
      "learning_rate": 4.232558139534884e-05,
      "loss": 35.309,
      "step": 130
    },
    {
      "epoch": 12.0,
      "eval_loss": 20.849153518676758,
      "eval_runtime": 0.3982,
      "eval_samples_per_second": 5.023,
      "eval_steps_per_second": 2.512,
      "step": 132
    },
    {
      "epoch": 12.272727272727273,
      "grad_norm": 133.75698852539062,
      "learning_rate": 4e-05,
      "loss": 32.9341,
      "step": 135
    },
    {
      "epoch": 12.727272727272727,
      "grad_norm": 528.655517578125,
      "learning_rate": 3.7674418604651165e-05,
      "loss": 38.3632,
      "step": 140
    },
    {
      "epoch": 13.0,
      "eval_loss": 20.7437801361084,
      "eval_runtime": 0.3998,
      "eval_samples_per_second": 5.002,
      "eval_steps_per_second": 2.501,
      "step": 143
    },
    {
      "epoch": 13.181818181818182,
      "grad_norm": 281.4421081542969,
      "learning_rate": 3.5348837209302326e-05,
      "loss": 37.6697,
      "step": 145
    },
    {
      "epoch": 13.636363636363637,
      "grad_norm": 855.7201538085938,
      "learning_rate": 3.302325581395349e-05,
      "loss": 37.9218,
      "step": 150
    },
    {
      "epoch": 14.0,
      "eval_loss": 20.688064575195312,
      "eval_runtime": 0.4012,
      "eval_samples_per_second": 4.985,
      "eval_steps_per_second": 2.493,
      "step": 154
    },
    {
      "epoch": 14.090909090909092,
      "grad_norm": 886.6594848632812,
      "learning_rate": 3.0697674418604656e-05,
      "loss": 32.1048,
      "step": 155
    },
    {
      "epoch": 14.545454545454545,
      "grad_norm": 326.5610656738281,
      "learning_rate": 2.8372093023255815e-05,
      "loss": 37.7966,
      "step": 160
    },
    {
      "epoch": 15.0,
      "grad_norm": 385.3919677734375,
      "learning_rate": 2.6046511627906976e-05,
      "loss": 31.9177,
      "step": 165
    },
    {
      "epoch": 15.0,
      "eval_loss": 20.718334197998047,
      "eval_runtime": 0.3963,
      "eval_samples_per_second": 5.046,
      "eval_steps_per_second": 2.523,
      "step": 165
    },
    {
      "epoch": 15.454545454545455,
      "grad_norm": 113.99037170410156,
      "learning_rate": 2.372093023255814e-05,
      "loss": 36.6998,
      "step": 170
    },
    {
      "epoch": 15.909090909090908,
      "grad_norm": 248.2681427001953,
      "learning_rate": 2.1395348837209303e-05,
      "loss": 33.8144,
      "step": 175
    },
    {
      "epoch": 16.0,
      "eval_loss": 20.68170166015625,
      "eval_runtime": 0.3979,
      "eval_samples_per_second": 5.027,
      "eval_steps_per_second": 2.513,
      "step": 176
    },
    {
      "epoch": 16.363636363636363,
      "grad_norm": 359.0174560546875,
      "learning_rate": 1.9069767441860468e-05,
      "loss": 39.702,
      "step": 180
    },
    {
      "epoch": 16.818181818181817,
      "grad_norm": 212.9514923095703,
      "learning_rate": 1.674418604651163e-05,
      "loss": 35.4798,
      "step": 185
    },
    {
      "epoch": 17.0,
      "eval_loss": 20.65376091003418,
      "eval_runtime": 0.3978,
      "eval_samples_per_second": 5.028,
      "eval_steps_per_second": 2.514,
      "step": 187
    },
    {
      "epoch": 17.272727272727273,
      "grad_norm": 212.5137481689453,
      "learning_rate": 1.4418604651162792e-05,
      "loss": 35.454,
      "step": 190
    },
    {
      "epoch": 17.727272727272727,
      "grad_norm": 382.6556701660156,
      "learning_rate": 1.2093023255813954e-05,
      "loss": 40.638,
      "step": 195
    },
    {
      "epoch": 18.0,
      "eval_loss": 20.598630905151367,
      "eval_runtime": 0.3978,
      "eval_samples_per_second": 5.027,
      "eval_steps_per_second": 2.514,
      "step": 198
    },
    {
      "epoch": 18.181818181818183,
      "grad_norm": 3031.1787109375,
      "learning_rate": 9.767441860465117e-06,
      "loss": 39.2177,
      "step": 200
    },
    {
      "epoch": 18.636363636363637,
      "grad_norm": 367.5917663574219,
      "learning_rate": 7.44186046511628e-06,
      "loss": 39.2546,
      "step": 205
    },
    {
      "epoch": 19.0,
      "eval_loss": 20.599620819091797,
      "eval_runtime": 0.3973,
      "eval_samples_per_second": 5.034,
      "eval_steps_per_second": 2.517,
      "step": 209
    },
    {
      "epoch": 19.09090909090909,
      "grad_norm": 385.84393310546875,
      "learning_rate": 5.116279069767442e-06,
      "loss": 36.6697,
      "step": 210
    },
    {
      "epoch": 19.545454545454547,
      "grad_norm": 1801.2802734375,
      "learning_rate": 2.7906976744186046e-06,
      "loss": 35.8831,
      "step": 215
    },
    {
      "epoch": 20.0,
      "grad_norm": 108.03319549560547,
      "learning_rate": 4.651162790697675e-07,
      "loss": 32.5717,
      "step": 220
    },
    {
      "epoch": 20.0,
      "eval_loss": 20.602333068847656,
      "eval_runtime": 0.3966,
      "eval_samples_per_second": 5.043,
      "eval_steps_per_second": 2.522,
      "step": 220
    }
  ],
  "logging_steps": 5,
  "max_steps": 220,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 20,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 11444702330880.0,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
