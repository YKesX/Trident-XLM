{
  "best_global_step": 240,
  "best_metric": 6.069694995880127,
  "best_model_checkpoint": "./flan_one_liner/checkpoint-240",
  "epoch": 20.0,
  "eval_steps": 500,
  "global_step": 240,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.4166666666666667,
      "grad_norm": 3.7325737476348877,
      "learning_rate": 8e-05,
      "loss": 18.7257,
      "step": 5
    },
    {
      "epoch": 0.8333333333333334,
      "grad_norm": 3.579850435256958,
      "learning_rate": 9.829787234042553e-05,
      "loss": 21.2844,
      "step": 10
    },
    {
      "epoch": 1.0,
      "eval_loss": 11.165204048156738,
      "eval_runtime": 0.2513,
      "eval_samples_per_second": 11.938,
      "eval_steps_per_second": 7.959,
      "step": 12
    },
    {
      "epoch": 1.25,
      "grad_norm": 4.8136820793151855,
      "learning_rate": 9.617021276595745e-05,
      "loss": 22.177,
      "step": 15
    },
    {
      "epoch": 1.6666666666666665,
      "grad_norm": 2.384192705154419,
      "learning_rate": 9.404255319148937e-05,
      "loss": 16.9682,
      "step": 20
    },
    {
      "epoch": 2.0,
      "eval_loss": 10.60197925567627,
      "eval_runtime": 0.2484,
      "eval_samples_per_second": 12.078,
      "eval_steps_per_second": 8.052,
      "step": 24
    },
    {
      "epoch": 2.0833333333333335,
      "grad_norm": 3.014749765396118,
      "learning_rate": 9.191489361702128e-05,
      "loss": 20.229,
      "step": 25
    },
    {
      "epoch": 2.5,
      "grad_norm": 4.323241710662842,
      "learning_rate": 8.978723404255319e-05,
      "loss": 19.0701,
      "step": 30
    },
    {
      "epoch": 2.9166666666666665,
      "grad_norm": 6.606440544128418,
      "learning_rate": 8.765957446808512e-05,
      "loss": 19.67,
      "step": 35
    },
    {
      "epoch": 3.0,
      "eval_loss": 9.971589088439941,
      "eval_runtime": 0.2633,
      "eval_samples_per_second": 11.392,
      "eval_steps_per_second": 7.595,
      "step": 36
    },
    {
      "epoch": 3.3333333333333335,
      "grad_norm": 5.294597148895264,
      "learning_rate": 8.553191489361702e-05,
      "loss": 18.7208,
      "step": 40
    },
    {
      "epoch": 3.75,
      "grad_norm": 3.8259153366088867,
      "learning_rate": 8.340425531914894e-05,
      "loss": 15.972,
      "step": 45
    },
    {
      "epoch": 4.0,
      "eval_loss": 9.356612205505371,
      "eval_runtime": 0.2735,
      "eval_samples_per_second": 10.967,
      "eval_steps_per_second": 7.312,
      "step": 48
    },
    {
      "epoch": 4.166666666666667,
      "grad_norm": 20.573694229125977,
      "learning_rate": 8.127659574468085e-05,
      "loss": 17.644,
      "step": 50
    },
    {
      "epoch": 4.583333333333333,
      "grad_norm": 5.598529815673828,
      "learning_rate": 7.914893617021277e-05,
      "loss": 16.3307,
      "step": 55
    },
    {
      "epoch": 5.0,
      "grad_norm": 5.19520902633667,
      "learning_rate": 7.702127659574469e-05,
      "loss": 16.4771,
      "step": 60
    },
    {
      "epoch": 5.0,
      "eval_loss": 8.8872709274292,
      "eval_runtime": 0.2497,
      "eval_samples_per_second": 12.015,
      "eval_steps_per_second": 8.01,
      "step": 60
    },
    {
      "epoch": 5.416666666666667,
      "grad_norm": 2.161475896835327,
      "learning_rate": 7.489361702127659e-05,
      "loss": 15.6395,
      "step": 65
    },
    {
      "epoch": 5.833333333333333,
      "grad_norm": 3.019820213317871,
      "learning_rate": 7.276595744680852e-05,
      "loss": 15.2342,
      "step": 70
    },
    {
      "epoch": 6.0,
      "eval_loss": 8.49524211883545,
      "eval_runtime": 0.2518,
      "eval_samples_per_second": 11.913,
      "eval_steps_per_second": 7.942,
      "step": 72
    },
    {
      "epoch": 6.25,
      "grad_norm": 5.402326583862305,
      "learning_rate": 7.063829787234042e-05,
      "loss": 16.7245,
      "step": 75
    },
    {
      "epoch": 6.666666666666667,
      "grad_norm": 4.892682075500488,
      "learning_rate": 6.851063829787234e-05,
      "loss": 14.1521,
      "step": 80
    },
    {
      "epoch": 7.0,
      "eval_loss": 8.188675880432129,
      "eval_runtime": 0.2498,
      "eval_samples_per_second": 12.008,
      "eval_steps_per_second": 8.005,
      "step": 84
    },
    {
      "epoch": 7.083333333333333,
      "grad_norm": 2.4677679538726807,
      "learning_rate": 6.638297872340426e-05,
      "loss": 14.1276,
      "step": 85
    },
    {
      "epoch": 7.5,
      "grad_norm": 3.3548014163970947,
      "learning_rate": 6.425531914893617e-05,
      "loss": 12.9898,
      "step": 90
    },
    {
      "epoch": 7.916666666666667,
      "grad_norm": 4.056378364562988,
      "learning_rate": 6.212765957446809e-05,
      "loss": 15.3201,
      "step": 95
    },
    {
      "epoch": 8.0,
      "eval_loss": 7.917025089263916,
      "eval_runtime": 0.2496,
      "eval_samples_per_second": 12.019,
      "eval_steps_per_second": 8.013,
      "step": 96
    },
    {
      "epoch": 8.333333333333334,
      "grad_norm": 4.813032627105713,
      "learning_rate": 6e-05,
      "loss": 13.2409,
      "step": 100
    },
    {
      "epoch": 8.75,
      "grad_norm": 4.499234676361084,
      "learning_rate": 5.787234042553191e-05,
      "loss": 14.2142,
      "step": 105
    },
    {
      "epoch": 9.0,
      "eval_loss": 7.645045757293701,
      "eval_runtime": 0.2502,
      "eval_samples_per_second": 11.991,
      "eval_steps_per_second": 7.994,
      "step": 108
    },
    {
      "epoch": 9.166666666666666,
      "grad_norm": 3.4745264053344727,
      "learning_rate": 5.5744680851063835e-05,
      "loss": 12.7117,
      "step": 110
    },
    {
      "epoch": 9.583333333333334,
      "grad_norm": 2.4768292903900146,
      "learning_rate": 5.3617021276595745e-05,
      "loss": 12.9743,
      "step": 115
    },
    {
      "epoch": 10.0,
      "grad_norm": 6.917179584503174,
      "learning_rate": 5.148936170212766e-05,
      "loss": 13.2393,
      "step": 120
    },
    {
      "epoch": 10.0,
      "eval_loss": 7.392140865325928,
      "eval_runtime": 0.2471,
      "eval_samples_per_second": 12.142,
      "eval_steps_per_second": 8.095,
      "step": 120
    },
    {
      "epoch": 10.416666666666666,
      "grad_norm": 20.433208465576172,
      "learning_rate": 4.936170212765958e-05,
      "loss": 13.8866,
      "step": 125
    },
    {
      "epoch": 10.833333333333334,
      "grad_norm": 3.7861077785491943,
      "learning_rate": 4.7234042553191496e-05,
      "loss": 10.5472,
      "step": 130
    },
    {
      "epoch": 11.0,
      "eval_loss": 7.173295974731445,
      "eval_runtime": 0.2504,
      "eval_samples_per_second": 11.981,
      "eval_steps_per_second": 7.988,
      "step": 132
    },
    {
      "epoch": 11.25,
      "grad_norm": 4.853895664215088,
      "learning_rate": 4.5106382978723406e-05,
      "loss": 12.8168,
      "step": 135
    },
    {
      "epoch": 11.666666666666666,
      "grad_norm": 6.733194828033447,
      "learning_rate": 4.297872340425532e-05,
      "loss": 10.8902,
      "step": 140
    },
    {
      "epoch": 12.0,
      "eval_loss": 6.950366973876953,
      "eval_runtime": 0.2482,
      "eval_samples_per_second": 12.086,
      "eval_steps_per_second": 8.058,
      "step": 144
    },
    {
      "epoch": 12.083333333333334,
      "grad_norm": 4.682364463806152,
      "learning_rate": 4.085106382978723e-05,
      "loss": 11.7236,
      "step": 145
    },
    {
      "epoch": 12.5,
      "grad_norm": 5.909327983856201,
      "learning_rate": 3.872340425531915e-05,
      "loss": 11.4597,
      "step": 150
    },
    {
      "epoch": 12.916666666666666,
      "grad_norm": 9.074079513549805,
      "learning_rate": 3.6595744680851066e-05,
      "loss": 11.7271,
      "step": 155
    },
    {
      "epoch": 13.0,
      "eval_loss": 6.76544713973999,
      "eval_runtime": 0.2506,
      "eval_samples_per_second": 11.972,
      "eval_steps_per_second": 7.981,
      "step": 156
    },
    {
      "epoch": 13.333333333333334,
      "grad_norm": 4.388980388641357,
      "learning_rate": 3.446808510638298e-05,
      "loss": 11.4544,
      "step": 160
    },
    {
      "epoch": 13.75,
      "grad_norm": 2.126424551010132,
      "learning_rate": 3.23404255319149e-05,
      "loss": 9.5183,
      "step": 165
    },
    {
      "epoch": 14.0,
      "eval_loss": 6.590022563934326,
      "eval_runtime": 0.2498,
      "eval_samples_per_second": 12.01,
      "eval_steps_per_second": 8.006,
      "step": 168
    },
    {
      "epoch": 14.166666666666666,
      "grad_norm": 2.0196447372436523,
      "learning_rate": 3.021276595744681e-05,
      "loss": 9.2478,
      "step": 170
    },
    {
      "epoch": 14.583333333333334,
      "grad_norm": 3.4828054904937744,
      "learning_rate": 2.8085106382978727e-05,
      "loss": 10.7867,
      "step": 175
    },
    {
      "epoch": 15.0,
      "grad_norm": 4.12291955947876,
      "learning_rate": 2.5957446808510637e-05,
      "loss": 10.9975,
      "step": 180
    },
    {
      "epoch": 15.0,
      "eval_loss": 6.438363552093506,
      "eval_runtime": 0.253,
      "eval_samples_per_second": 11.856,
      "eval_steps_per_second": 7.904,
      "step": 180
    },
    {
      "epoch": 15.416666666666666,
      "grad_norm": 5.3488850593566895,
      "learning_rate": 2.3829787234042557e-05,
      "loss": 10.1887,
      "step": 185
    },
    {
      "epoch": 15.833333333333334,
      "grad_norm": 4.6007561683654785,
      "learning_rate": 2.170212765957447e-05,
      "loss": 10.9746,
      "step": 190
    },
    {
      "epoch": 16.0,
      "eval_loss": 6.3067307472229,
      "eval_runtime": 0.2493,
      "eval_samples_per_second": 12.035,
      "eval_steps_per_second": 8.024,
      "step": 192
    },
    {
      "epoch": 16.25,
      "grad_norm": 4.816933631896973,
      "learning_rate": 1.9574468085106384e-05,
      "loss": 8.9761,
      "step": 195
    },
    {
      "epoch": 16.666666666666668,
      "grad_norm": 4.305787563323975,
      "learning_rate": 1.74468085106383e-05,
      "loss": 10.1494,
      "step": 200
    },
    {
      "epoch": 17.0,
      "eval_loss": 6.202520847320557,
      "eval_runtime": 0.2487,
      "eval_samples_per_second": 12.063,
      "eval_steps_per_second": 8.042,
      "step": 204
    },
    {
      "epoch": 17.083333333333332,
      "grad_norm": 5.274159908294678,
      "learning_rate": 1.5319148936170214e-05,
      "loss": 11.2874,
      "step": 205
    },
    {
      "epoch": 17.5,
      "grad_norm": 2.949662685394287,
      "learning_rate": 1.3191489361702127e-05,
      "loss": 9.425,
      "step": 210
    },
    {
      "epoch": 17.916666666666668,
      "grad_norm": 3.6379613876342773,
      "learning_rate": 1.1063829787234042e-05,
      "loss": 10.0469,
      "step": 215
    },
    {
      "epoch": 18.0,
      "eval_loss": 6.128362655639648,
      "eval_runtime": 0.2496,
      "eval_samples_per_second": 12.02,
      "eval_steps_per_second": 8.013,
      "step": 216
    },
    {
      "epoch": 18.333333333333332,
      "grad_norm": 4.910300254821777,
      "learning_rate": 8.936170212765958e-06,
      "loss": 9.6546,
      "step": 220
    },
    {
      "epoch": 18.75,
      "grad_norm": 18.757850646972656,
      "learning_rate": 6.808510638297873e-06,
      "loss": 10.3465,
      "step": 225
    },
    {
      "epoch": 19.0,
      "eval_loss": 6.0853118896484375,
      "eval_runtime": 0.2495,
      "eval_samples_per_second": 12.024,
      "eval_steps_per_second": 8.016,
      "step": 228
    },
    {
      "epoch": 19.166666666666668,
      "grad_norm": 5.16925573348999,
      "learning_rate": 4.680851063829787e-06,
      "loss": 9.9686,
      "step": 230
    },
    {
      "epoch": 19.583333333333332,
      "grad_norm": 4.405375957489014,
      "learning_rate": 2.553191489361702e-06,
      "loss": 10.2652,
      "step": 235
    },
    {
      "epoch": 20.0,
      "grad_norm": 5.849362850189209,
      "learning_rate": 4.2553191489361704e-07,
      "loss": 8.9505,
      "step": 240
    },
    {
      "epoch": 20.0,
      "eval_loss": 6.069694995880127,
      "eval_runtime": 0.2511,
      "eval_samples_per_second": 11.946,
      "eval_steps_per_second": 7.964,
      "step": 240
    }
  ],
  "logging_steps": 5,
  "max_steps": 240,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 20,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 7310742405120.0,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
